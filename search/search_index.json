{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Vector Graph RAG","text":"<p>Graph RAG with pure vector search \u2014 no graph database needed, single-pass LLM reranking, optimized for knowledge-intensive domains.</p>"},{"location":"#why-vector-graph-rag","title":"Why Vector Graph RAG?","text":"<p>Most Graph RAG systems require a dedicated graph database (Neo4j, etc.) and complex multi-step retrieval with iterative LLM calls. Vector Graph RAG takes a fundamentally different approach:</p> <ul> <li>No graph database \u2014 The entire knowledge graph lives in Milvus as vectors. No extra infrastructure, no schema management, no graph query language.</li> <li>Single-pass reranking \u2014 Unlike agentic approaches (IRCoT, multi-step reflection), we call the LLM just once to rerank candidate relations. This is simpler, faster, and cheaper.</li> <li>Knowledge-intensive friendly \u2014 Designed for domains where dense factual knowledge matters: legal documents, financial reports, medical literature, novels, and more.</li> </ul>"},{"location":"#features","title":"Features","text":"No Graph Database Pure vector search with Milvus \u2014 no Neo4j, no ArangoDB, no extra infra Single-Pass Reranking One LLM call, no iterative agent loops like IRCoT Knowledge-Intensive Optimized for legal, finance, medical, literature domains Zero Configuration Milvus Lite by default, works out of the box Multi-hop Reasoning Subgraph expansion for complex multi-hop QA State-of-the-Art 87.8% avg Recall@5 on standard benchmarks"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from vector_graph_rag import VectorGraphRAG\n\nrag = VectorGraphRAG()  # reads OPENAI_API_KEY from environment\n\nrag.add_texts([\n    \"Albert Einstein developed the theory of relativity.\",\n    \"The theory of relativity revolutionized our understanding of space and time.\",\n])\n\nresult = rag.query(\"What did Einstein develop?\")\nprint(result.answer)\n</code></pre>"},{"location":"#performance","title":"Performance","text":"Method MuSiQue HotpotQA 2WikiMultiHopQA Average Naive RAG 55.6% 90.8% 73.7% 73.4% IRCoT + HippoRAG 57.6% 83.0% 93.9% 78.2% HippoRAG 2 74.7% 96.3% 90.4% 87.1% Vector Graph RAG 73.0% 96.3% 94.1% 87.8% <p>See Evaluation for details.</p>"},{"location":"evaluation/","title":"Evaluation","text":"<p>Vector Graph RAG is evaluated on three standard multi-hop QA benchmarks.</p>"},{"location":"evaluation/#datasets","title":"Datasets","text":"Dataset Description Hop Count MuSiQue Multi-hop questions requiring 2\u20134 reasoning steps 2\u20134 hops HotpotQA Wikipedia-based multi-hop QA 2 hops 2WikiMultiHopQA Cross-document reasoning over Wikipedia 2 hops <p>Metric: Recall@5 \u2014 whether the ground-truth supporting passages appear within the top-5 retrieved results.</p>"},{"location":"evaluation/#results","title":"Results","text":""},{"location":"evaluation/#recall5-vs-naive-rag","title":"Recall@5 vs. Naive RAG","text":"Method MuSiQue HotpotQA 2WikiMultiHopQA Average Naive RAG 55.6% 90.8% 73.7% 73.4% Vector Graph RAG 73.0% 96.3% 94.1% 87.8% Improvement +31.4% +6.1% +27.7% +19.6%"},{"location":"evaluation/#comparison-with-state-of-the-art","title":"Comparison with State-of-the-Art","text":"Method MuSiQue HotpotQA 2WikiMultiHopQA Average HippoRAG (ColBERTv2)\u00b9 51.9% 77.7% 89.1% 72.9% IRCoT + HippoRAG\u00b9 57.6% 83.0% 93.9% 78.2% NV-Embed-v2\u00b2 69.7% 94.5% 76.5% 80.2% HippoRAG 2\u00b2 74.7% 96.3% 90.4% 87.1% Vector Graph RAG 73.0% 96.3% 94.1% 87.8% <p>\u00b9 HippoRAG: Neurobiologically Inspired Long-Term Memory for LLMs (NeurIPS 2024) \u00b2 From RAG to Memory: Non-Parametric Continual Learning for LLMs (2025)</p>"},{"location":"evaluation/#methodology","title":"Methodology","text":"<p>For fair comparison with HippoRAG, we use the same pre-extracted triplets from HippoRAG's repository rather than re-extracting them. This ensures the evaluation isolates the retrieval algorithm improvements without interference from triplet extraction quality differences.</p>"},{"location":"evaluation/#reproduction","title":"Reproduction","text":"<p>See <code>evaluation/README.md</code> for full reproduction steps.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"pipuv <pre><code>pip install vector-graph-rag\n</code></pre> <pre><code>uv add vector-graph-rag\n</code></pre>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<pre><code>from vector_graph_rag import VectorGraphRAG\n\nrag = VectorGraphRAG()  # reads OPENAI_API_KEY from environment\n\nrag.add_texts([\n    \"Albert Einstein developed the theory of relativity.\",\n    \"The theory of relativity revolutionized our understanding of space and time.\",\n])\n\nresult = rag.query(\"What did Einstein develop?\")\nprint(result.answer)\n</code></pre> <p>Note</p> <p>Set the <code>OPENAI_API_KEY</code> environment variable before running.</p>"},{"location":"getting-started/#configuration","title":"Configuration","text":""},{"location":"getting-started/#basic","title":"Basic","text":"<pre><code>rag = VectorGraphRAG(\n    milvus_uri=\"./my_data.db\",       # local file (Milvus Lite)\n    llm_model=\"gpt-4o\",\n    embedding_model=\"text-embedding-3-large\",\n)\n</code></pre>"},{"location":"getting-started/#with-remote-milvus","title":"With Remote Milvus","text":"<pre><code>rag = VectorGraphRAG(\n    milvus_uri=\"http://localhost:19530\",\n    milvus_db=\"my_database\",           # optional: specify database\n    collection_prefix=\"my_project\",    # optional: isolate collections\n)\n</code></pre> <p>Collections will be named <code>my_project_vgrag_entities</code>, <code>my_project_vgrag_relations</code>, <code>my_project_vgrag_passages</code>.</p>"},{"location":"getting-started/#multiple-knowledge-bases","title":"Multiple Knowledge Bases","text":"<p>Use <code>collection_prefix</code> to maintain separate graphs in the same Milvus instance:</p> <pre><code># Different documents \u2192 different prefixes\nlegal_rag = VectorGraphRAG(milvus_uri=\"./data.db\", collection_prefix=\"legal\")\nfinance_rag = VectorGraphRAG(milvus_uri=\"./data.db\", collection_prefix=\"finance\")\n</code></pre>"},{"location":"getting-started/#with-pre-extracted-triplets","title":"With Pre-extracted Triplets","text":"<p>Skip LLM extraction if you already have knowledge graph triplets:</p> <pre><code>rag.add_documents_with_triplets([\n    {\n        \"passage\": \"Einstein developed relativity at Princeton.\",\n        \"triplets\": [\n            [\"Einstein\", \"developed\", \"relativity\"],\n            [\"Einstein\", \"worked at\", \"Princeton\"],\n        ],\n    },\n])\n</code></pre>"},{"location":"getting-started/#import-from-urls-and-files","title":"Import from URLs and Files","text":"<p>Import web pages, PDFs, and other documents with automatic chunking:</p> <pre><code>pip install \"vector-graph-rag[loaders]\"\n</code></pre> <pre><code>from vector_graph_rag import VectorGraphRAG\nfrom vector_graph_rag.loaders import DocumentImporter\n\n# Import from URLs, PDFs, DOCX, etc. (with automatic chunking)\nimporter = DocumentImporter(chunk_size=1000, chunk_overlap=200)\nresult = importer.import_sources([\n    \"https://en.wikipedia.org/wiki/Albert_Einstein\",\n    \"/path/to/document.pdf\",\n    \"/path/to/report.docx\",\n])\n\nrag = VectorGraphRAG(milvus_uri=\"./my_graph.db\")\nrag.add_documents(result.documents, extract_triplets=True)\n\n# Query\nresult = rag.query(\"What did Einstein discover?\")\nprint(result.answer)\n</code></pre>"},{"location":"getting-started/#rest-api","title":"REST API","text":"<p>Run the API server for programmatic access:</p> <pre><code>uv sync --extra api\nuv run uvicorn api.main:app --host 0.0.0.0 --port 8000\n</code></pre> Endpoint Method Description <code>/health</code> GET Health check <code>/graphs</code> GET List available graphs <code>/stats</code> GET Get graph statistics <code>/query</code> POST Query the knowledge graph <code>/add_documents</code> POST Add documents <p>API docs are available at <code>http://localhost:8000/docs</code> after starting the server.</p>"},{"location":"how-it-works/","title":"How It Works","text":""},{"location":"how-it-works/#design-philosophy","title":"Design Philosophy","text":"<p>Vector Graph RAG is built on three key principles:</p>"},{"location":"how-it-works/#1-no-graph-database","title":"1. No Graph Database","text":"<p>Traditional Graph RAG systems store knowledge in a graph database (Neo4j, ArangoDB, etc.) and use graph traversal queries (Cypher, Gremlin) to retrieve relevant subgraphs. This adds operational complexity: another database to deploy, a query language to learn, schema to maintain.</p> <p>We store the entire knowledge graph \u2014 entities, relations, and passages \u2014 as vectors in Milvus. Retrieval becomes vector similarity search, which is simple, scalable, and requires no additional infrastructure.</p>"},{"location":"how-it-works/#2-single-pass-llm-reranking","title":"2. Single-Pass LLM Reranking","text":"<p>Many RAG systems use iterative, agentic retrieval \u2014 the LLM decides what to retrieve next, reflects on results, and repeats. For example:</p> <ul> <li>IRCoT (Interleaving Retrieval with Chain-of-Thought) alternates between retrieval and reasoning over multiple rounds</li> <li>Self-RAG uses the LLM to critique and re-retrieve documents</li> <li>Agentic RAG gives the LLM tools to search iteratively</li> </ul> <p>These approaches are powerful but expensive \u2014 each iteration costs an LLM call, adding latency and cost.</p> <p>Vector Graph RAG uses a single LLM reranking pass. After vector search and subgraph expansion produce candidate relations, the LLM scores them once. This is sufficient because the vector search + subgraph expansion already provides high-quality candidates, and a single reranking step can effectively filter the best results.</p>"},{"location":"how-it-works/#3-knowledge-intensive-domains","title":"3. Knowledge-Intensive Domains","text":"<p>Vector Graph RAG is especially effective for knowledge-intensive content \u2014 documents where dense factual relationships are the core value:</p> Domain Why Graph RAG Helps Legal Statutes reference other statutes, precedents cite precedents \u2014 graph captures these cross-references Finance Company relationships, ownership chains, transaction flows form natural graphs Medical Drug interactions, symptom-disease-treatment pathways are inherently relational Literature Character relationships, plot connections, thematic links across chapters Academic Citation networks, concept dependencies, methodology chains <p>In these domains, naive RAG often fails because the answer requires connecting facts across multiple documents. The knowledge graph captures these connections explicitly.</p>"},{"location":"how-it-works/#architecture","title":"Architecture","text":""},{"location":"how-it-works/#indexing-pipeline","title":"Indexing Pipeline","text":"<pre><code>flowchart LR\n    A[Documents] --&gt; B[Triplet Extraction\\n**LLM**]\n    B --&gt; C[Entities + Relations]\n    C --&gt; D[Embedding]\n    D --&gt; E[Milvus]</code></pre> <ol> <li>Triplet Extraction \u2014 An LLM extracts <code>(subject, predicate, object)</code> triplets from each document.</li> <li>Entity &amp; Relation Storage \u2014 Entities and relations are stored as vectors in Milvus collections.</li> <li>Embedding \u2014 All text is embedded for vector similarity search.</li> </ol>"},{"location":"how-it-works/#query-pipeline","title":"Query Pipeline","text":"<pre><code>flowchart LR\n    A[Question] --&gt; B[Entity Extraction]\n    B --&gt; C[Vector Search]\n    C --&gt; D[Subgraph Expansion]\n    D --&gt; E[LLM Reranking]\n    E --&gt; F[Answer]</code></pre> <ol> <li>Entity Extraction \u2014 Extract key entities from the user's question.</li> <li>Vector Search \u2014 Find similar entities and relations in Milvus.</li> <li>Subgraph Expansion \u2014 Collect candidate relations by expanding around matched entities.</li> <li>LLM Reranking \u2014 Use an LLM to score and filter the most relevant relations (single pass).</li> <li>Answer Generation \u2014 Generate the final answer from the selected context.</li> </ol>"},{"location":"how-it-works/#worked-example","title":"Worked Example","text":""},{"location":"how-it-works/#indexing","title":"Indexing","text":"<p>Given the passage: \"Einstein developed the theory of relativity at Princeton.\"</p> <ul> <li>Entities: <code>Einstein</code>, <code>theory of relativity</code>, <code>Princeton</code></li> <li>Relations:<ul> <li><code>(Einstein, developed, theory of relativity)</code></li> <li><code>(Einstein, worked at, Princeton)</code></li> </ul> </li> </ul>"},{"location":"how-it-works/#querying","title":"Querying","text":"<p>For the question: \"What did Einstein develop?\"</p> <pre><code>flowchart TD\n    Q[\"What did Einstein develop?\"] --&gt; E1[\"Extract entity: **Einstein**\"]\n    E1 --&gt; VS[\"Vector search \u2192 similar entities\"]\n    VS --&gt; SE[\"Subgraph expansion \u2192 candidate relations\"]\n    SE --&gt; R1[\"(Einstein, developed, theory of relativity)\"]\n    SE --&gt; R2[\"(Einstein, worked at, Princeton)\"]\n    R1 --&gt; LLM[\"LLM reranking (single pass)\"]\n    R2 --&gt; LLM\n    LLM --&gt; A[\"Einstein developed the theory of relativity.\"]</code></pre> <ol> <li>Extract entity: <code>Einstein</code></li> <li>Vector search finds similar entities and relations</li> <li>Subgraph expansion collects candidate relations</li> <li>LLM reranking selects <code>(Einstein, developed, theory of relativity)</code> \u2014 one call, no iteration</li> <li>Generate answer: \"Einstein developed the theory of relativity.\"</li> </ol>"},{"location":"how-it-works/#comparison-with-other-approaches","title":"Comparison with Other Approaches","text":"Approach Graph DB LLM Calls per Query Iterative Complexity Naive RAG No 1 (generation) No Low IRCoT No Multiple (retrieve + reason loops) Yes High HippoRAG No 1-2 No Medium Microsoft GraphRAG Yes (Neo4j) Multiple Yes High Vector Graph RAG No 2 (rerank + generation) No Low"},{"location":"use-cases/","title":"Use Cases","text":"<p>Vector Graph RAG is designed for knowledge-intensive domains where documents contain dense factual relationships and answers often require connecting information across multiple sources.</p>"},{"location":"use-cases/#when-to-use-graph-rag-vs-naive-rag","title":"When to Use Graph RAG vs Naive RAG","text":"<p>Use Naive RAG when:</p> <ul> <li>Questions can be answered from a single passage</li> <li>Content is self-contained (e.g., FAQ, product docs)</li> <li>Low latency is critical and accuracy trade-off is acceptable</li> </ul> <p>Use Vector Graph RAG when:</p> <ul> <li>Answers require connecting facts across multiple documents</li> <li>Content has rich entity relationships (people, organizations, concepts)</li> <li>Multi-hop reasoning is needed (\"Who worked with X at Y?\")</li> <li>Domain has dense factual knowledge</li> </ul>"},{"location":"use-cases/#domain-examples","title":"Domain Examples","text":""},{"location":"use-cases/#legal","title":"Legal","text":"<p>Legal documents are full of cross-references: statutes cite other statutes, court opinions reference precedents, contracts refer to defined terms across sections.</p> <pre><code>rag = VectorGraphRAG(collection_prefix=\"legal_contracts\")\n\nrag.add_texts([\n    \"Section 3.1 defines the indemnification obligations of the Seller.\",\n    \"Under Section 5.2, breach of Section 3.1 triggers termination rights.\",\n    \"The Buyer may exercise termination rights within 30 days of notice.\",\n])\n\nresult = rag.query(\"What happens if the Seller breaches indemnification obligations?\")\n# Graph connects: Seller \u2192 indemnification (3.1) \u2192 breach triggers termination (5.2) \u2192 30 days\n</code></pre>"},{"location":"use-cases/#finance","title":"Finance","text":"<p>Financial data forms natural graphs: companies own subsidiaries, executives serve on boards, transactions flow between entities.</p> <pre><code>rag = VectorGraphRAG(collection_prefix=\"financial_reports\")\n\nrag.add_texts([\n    \"Berkshire Hathaway acquired See's Candies in 1972 for $25 million.\",\n    \"See's Candies generated $383 million in pre-tax earnings by 2007.\",\n    \"Warren Buffett has called See's the ideal business.\",\n])\n\nresult = rag.query(\"How has Berkshire's candy acquisition performed?\")\n# Graph connects: Berkshire \u2192 acquired See's \u2192 earnings growth \u2192 Buffett's assessment\n</code></pre>"},{"location":"use-cases/#medical-biomedical","title":"Medical &amp; Biomedical","text":"<p>Drug interactions, symptom-disease-treatment pathways, and clinical trial relationships are inherently relational.</p> <pre><code>rag = VectorGraphRAG(collection_prefix=\"medical_literature\")\n\nrag.add_texts([\n    \"Metformin is the first-line treatment for type 2 diabetes.\",\n    \"Patients on metformin should have renal function monitored.\",\n    \"Impaired renal function may require dose adjustment or alternative therapy.\",\n])\n\nresult = rag.query(\"What monitoring is needed for first-line diabetes treatment?\")\n# Graph connects: diabetes \u2192 metformin (first-line) \u2192 renal monitoring \u2192 dose adjustment\n</code></pre>"},{"location":"use-cases/#literature-novels","title":"Literature &amp; Novels","text":"<p>Character relationships, plot events, and thematic connections across chapters benefit from graph representation.</p> <pre><code>from vector_graph_rag.loaders import DocumentImporter\n\nimporter = DocumentImporter(chunk_size=1500, chunk_overlap=200)\nresult = importer.import_sources([\"/path/to/novel.pdf\"])\n\nrag = VectorGraphRAG(collection_prefix=\"novel_analysis\")\nrag.add_documents(result.documents, extract_triplets=True)\n\nresult = rag.query(\"How does the protagonist's relationship with the antagonist evolve?\")\n# Graph captures character interactions across the entire novel\n</code></pre>"},{"location":"use-cases/#academic-research","title":"Academic Research","text":"<p>Citation networks, concept dependencies, and cross-paper methodology comparisons.</p> <pre><code>from vector_graph_rag.loaders import DocumentImporter\n\nimporter = DocumentImporter(chunk_size=1000, chunk_overlap=200)\nresult = importer.import_sources([\n    \"/path/to/paper1.pdf\",\n    \"/path/to/paper2.pdf\",\n    \"/path/to/paper3.pdf\",\n])\n\nrag = VectorGraphRAG(collection_prefix=\"research_survey\")\nrag.add_documents(result.documents, extract_triplets=True)\n\nresult = rag.query(\"What methods achieve the best performance on this task?\")\n# Graph connects methods, results, and comparisons across papers\n</code></pre>"},{"location":"use-cases/#organizing-multiple-knowledge-bases","title":"Organizing Multiple Knowledge Bases","text":"<p>Use <code>collection_prefix</code> to separate different document sets in the same Milvus instance:</p> <pre><code># Each domain gets its own isolated graph\nlegal_rag = VectorGraphRAG(milvus_uri=\"http://localhost:19530\", collection_prefix=\"legal\")\nfinance_rag = VectorGraphRAG(milvus_uri=\"http://localhost:19530\", collection_prefix=\"finance\")\nmedical_rag = VectorGraphRAG(milvus_uri=\"http://localhost:19530\", collection_prefix=\"medical\")\n</code></pre> <p>Or use <code>milvus_db</code> for database-level isolation:</p> <pre><code>rag = VectorGraphRAG(\n    milvus_uri=\"http://localhost:19530\",\n    milvus_db=\"production\",\n    collection_prefix=\"legal_v2\",\n)\n</code></pre>"}]}